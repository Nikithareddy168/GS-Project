{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapReduce Paradigm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MapReduce basically does two things \"maps data\" and \"reduces data\". When we get data line by line, MapReduce transforms the data and extract the values/data it carries and then aggregates it into a stucture that makes sense.\n",
    "\n",
    "Mapper takes the input data and converts it into key/value pairs. Where as Reduces aggregates into a structured form. Before reducer there is 'shuffle and sort' phase where sorting of the data coming from the mapper will be done and then passed to reducer phase. This pretty much what a MapReduce program does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am going to explain MapReduce paradigm by applying it on the movielens dataset. I have taken this dataset from the link https://grouplens.org/datasets/movielens/100k/. In this we can find any size of the dataset but, since I am working on just a single PC, I have chosen an older dataset(i.e movielens 100K) which is of size 5MB. This dataset contains around 100,000 ratings on 1700 movies from nearly 1000 users. This dataset contains contains u.data file which contains the users rating for movies. It has attributes like USER_ID, MOVIE_ID, RATING(on a scale of five) and TIMESTAMP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My task is to find the total number of each ratings type from the u.data file using MapReduce paradigm. For this, I am going to use a framwork called \"MRJob\". As a hig level overview, MRJob is a framework that allows us to perform mapreduce jobs without even installing it in our local machine but, allow us to run the jobs on our cluster. There are other frameworks like Dumbo and Pydoop that can perform the MapReduce jobs but the benefits over using MRjob over the other two frameworks are like mrjob provides proper documentation, can run the jobs locally without hadoop and debugging will be easier. Only thing that MRJob doesn't provide is the same level of access to Hadoop APIs like other frameworks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using MRJob it is required to install it using the command \"pip install mrjob\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For running the mrjob we need to write the code in '.py' file. I jupyter notebook this can be done using \"%% writefile filename.py\" and then write the content into the file and save it. Now, load it into the cell using \" %load file_path\". In my case since I stored it in a folder named code, I am giving \" %load code\\Ratings.py\"\n",
    "\n",
    "Now, to run the code use \"%run code_path data_path\" like for me it's \"%run code/Ratings.py data/u.data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach for the below code is, since our goal to find the total number of 1 star,2-star, 3-star, 4-star, 5-star ratings we are gonna extract the ratings from the data by splitting up the data in the mapper function and assign each rating 1 as the value.Once the mapping is done, shuffle and sort will be done in the backgroud by MapReduce. so, now the reducer can sum up all the 1s with same keys and output the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: usage: ipykernel_launcher.py [options] [input files]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikit\\Anaconda3\\envs\\Basic RecSys\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2886: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# %load code\\Ratings.py\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep ## Tells the framework what functions are used for mappers and reducers in our jobs\n",
    "\n",
    "class Ratings(MRJob): # MRjob wrapped in a class named Ratings\n",
    "    def steps(self): # I just have single step of  mrjob\n",
    "        return [MRStep(mapper = self.ratingsMapper, reducer = self.ratingsReducer)]\n",
    "    \n",
    "    def ratingsMapper(self, _, line): \n",
    "        (userID, movieID, rating, timestamp) = line.split('\\t') # extracting each column to a tuple\n",
    "        yield rating,1\n",
    "    \n",
    "    def ratingsReducer(self, key, values): # reducer function will be called once for each unique key\n",
    "        yield key, sum(values)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    Ratings.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Running step 1 of 1...\n",
      "Creating temp directory c:\\users\\nikit\\appdata\\local\\temp\\Ratings.nikit.20181022.030233.851000\n",
      "Streaming final output from c:\\users\\nikit\\appdata\\local\\temp\\Ratings.nikit.20181022.030233.851000\\output...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"1\"\t6110\n",
      "\"2\"\t11370\n",
      "\"3\"\t27145\n",
      "\"4\"\t34174\n",
      "\"5\"\t21201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Removing temp directory c:\\users\\nikit\\appdata\\local\\temp\\Ratings.nikit.20181022.030233.851000...\n",
      "[Error 5] Access is denied: u'c:\\\\users\\\\nikit\\\\appdata\\\\local\\\\temp\\\\Ratings.nikit.20181022.030233.851000\\\\step\\\\000\\\\cache\\\\Ratings.py'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\nikit\\Anaconda3\\envs\\Basic RecSys\\lib\\site-packages\\mrjob\\runner.py\", line 606, in _cleanup_local_tmp\n",
      "    shutil.rmtree(self._local_tmp_dir)\n",
      "  File \"C:\\Users\\nikit\\Anaconda3\\envs\\Basic RecSys\\lib\\shutil.py\", line 261, in rmtree\n",
      "    rmtree(fullname, ignore_errors, onerror)\n",
      "  File \"C:\\Users\\nikit\\Anaconda3\\envs\\Basic RecSys\\lib\\shutil.py\", line 261, in rmtree\n",
      "    rmtree(fullname, ignore_errors, onerror)\n",
      "  File \"C:\\Users\\nikit\\Anaconda3\\envs\\Basic RecSys\\lib\\shutil.py\", line 261, in rmtree\n",
      "    rmtree(fullname, ignore_errors, onerror)\n",
      "  File \"C:\\Users\\nikit\\Anaconda3\\envs\\Basic RecSys\\lib\\shutil.py\", line 266, in rmtree\n",
      "    onerror(os.remove, fullname, sys.exc_info())\n",
      "  File \"C:\\Users\\nikit\\Anaconda3\\envs\\Basic RecSys\\lib\\shutil.py\", line 264, in rmtree\n",
      "    os.remove(fullname)\n",
      "WindowsError: [Error 5] Access is denied: u'c:\\\\users\\\\nikit\\\\appdata\\\\local\\\\temp\\\\Ratings.nikit.20181022.030233.851000\\\\step\\\\000\\\\cache\\\\Ratings.py'\n"
     ]
    }
   ],
   "source": [
    "%run code/Ratings.py data/u.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
